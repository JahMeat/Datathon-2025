{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8067b9c",
   "metadata": {},
   "source": [
    "# **Predicting Seattle Resident's Customer Requests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "65af1655",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install lightgbm xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a6cc5a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Cross-validation\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "import time\n",
    "\n",
    "# Ignore Unhelpful Warnings\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from scipy.stats import randint, uniform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "681728d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Customer_Service_Requests_20250426.csv\", low_memory=False)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2098cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_na = df.isna().sum().max()\n",
    "total_count = df.shape[0]\n",
    "percent_missing = (max_na / total_count) * 100\n",
    "\n",
    "print(f\"There are a total of {total_count} observations with {max_na} observations that has at least one feature with missing data.\", end=\"\\n\")\n",
    "print(f\"{percent_missing:.2f}% of the data would be removed if we were to account for all features with missing data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a4d44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d33a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873f3746",
   "metadata": {},
   "source": [
    "### Predict the Total Service Requests in the next 3 Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1498913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Created Date column into a datetime object\n",
    "df['Created Date'] = pd.to_datetime(df['Created Date'])\n",
    "\n",
    "# Now you can safely extract all the time features\n",
    "df['year'] = df['Created Date'].dt.year\n",
    "df['month'] = df['Created Date'].dt.month\n",
    "df['day'] = df['Created Date'].dt.day\n",
    "df['day_of_week'] = df['Created Date'].dt.dayofweek  # 0 = Monday, 6 = Sunday\n",
    "df['week_of_year'] = df['Created Date'].dt.isocalendar().week\n",
    "df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "874e8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Service_Type = df.groupby(['Service Request Type', 'year', 'month', 'day', 'day_of_week', 'week_of_year', 'is_weekend'])['Service Request Number'].count().reset_index()\n",
    "Service_Type.rename(columns={'Service Request Number': 'Request Count'}, inplace=True)\n",
    "\n",
    "Service_Type.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aa620eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Recreate a proper datetime column from year, month, day\n",
    "Service_Type['Created Date'] = pd.to_datetime(Service_Type[['year', 'month', 'day']])\n",
    "\n",
    "# 2. Sort correctly by Service Request Type and Date\n",
    "Service_Type = Service_Type.sort_values(['Service Request Type', 'Created Date'])\n",
    "\n",
    "# 3. Now create lag features based on Request Count\n",
    "Service_Type['Daily_lag'] = Service_Type['Request Count'].shift(1)\n",
    "Service_Type['Weekly_lag'] = Service_Type['Request Count'].shift(7)\n",
    "\n",
    "# 4. Add rolling averages if you want\n",
    "Service_Type['rolling_mean_7'] = Service_Type['Request Count'].rolling(window=7, min_periods=1).mean().reset_index(0, drop=True)\n",
    "Service_Type['rolling_std_7'] = Service_Type['Request Count'].rolling(window=7, min_periods=1).std().reset_index(0, drop=True)\n",
    "\n",
    "Service_Type = Service_Type.fillna(0)\n",
    "Service_Type[['Daily_lag', 'Weekly_lag']] = Service_Type[['Daily_lag', 'Weekly_lag']].astype(int)\n",
    "\n",
    "\n",
    "Service_Type.sample(20)\n",
    "\n",
    "Service_Type = Service_Type.drop(columns=['Created Date'])\n",
    "\n",
    "Service_Type.sample(10)\n",
    "\n",
    "safe_routes_df = Service_Type[\n",
    "    Service_Type['Service Request Type'] == 'Safe Routes to School' # ) &\n",
    "    # Service_Type['Request Count'] == 1\n",
    "]\n",
    "\n",
    "safe_routes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c773fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_types = Service_Type['Service Request Type'].unique()\n",
    "\n",
    "\n",
    "model_df = pd.DataFrame(service_types, columns=['Service Request Type'])\n",
    "model_df['Model'] = None\n",
    "model_df['Mean Absolute Error'] = None\n",
    "model_df['Mean Absolute Percentage Error'] = None\n",
    "model_df['Latency'] = None\n",
    "\n",
    "model_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e63c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_split = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "param_dist = {\n",
    "    'Linear Regression': {\n",
    "        # very few hyper‐params here\n",
    "        'fit_intercept': [True, False],\n",
    "        'normalize':     [True, False]  \n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators':    randint(50, 500),\n",
    "        'max_depth':       randint(3, 20),\n",
    "        'min_samples_split': randint(2, 10),\n",
    "        'min_samples_leaf':  randint(1, 10),\n",
    "        'max_features':    ['auto', 'sqrt', 'log2']\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators':    randint(50, 500),\n",
    "        'num_leaves':      randint(10, 200),\n",
    "        'learning_rate':   uniform(0.01, 0.3),\n",
    "        'min_child_samples': randint(5, 50),\n",
    "        'subsample':       uniform(0.5, 0.5)\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators':    randint(50, 500),\n",
    "        'max_depth':       randint(3, 20),\n",
    "        'learning_rate':   uniform(0.01, 0.3),\n",
    "        'subsample':       uniform(0.5, 0.5),\n",
    "        'colsample_bytree':uniform(0.5, 0.5)\n",
    "    }\n",
    "}\n",
    "\n",
    "# 3) Set up your CV splitter & random search kwargs\n",
    "cv_split = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "search_kwargs = dict(\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=cv,\n",
    "    n_iter=20,            # number of random draws\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4) Run RandomizedSearchCV for each model\n",
    "best_searches = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n▶️ Tuning {name}...\")\n",
    "    rs = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_dist[name],\n",
    "        **search_kwargs\n",
    "    )\n",
    "    rs.fit(X_train, y_train)            # use your training set here\n",
    "    best_searches[name] = rs\n",
    "    print(f\"→ {name} best MAE = {-rs.best_score_:.3f}\")\n",
    "    print(f\"  best params = {rs.best_params_}\")\n",
    "\n",
    "# 5) Extract the best estimators & retrain / evaluate on your hold-out test set\n",
    "for name, rs in best_searches.items():\n",
    "    print(f\"\\n{name} on TEST set:\")\n",
    "    best = rs.best_estimator_\n",
    "    y_pred = best.predict(X_hot_test)\n",
    "    mae = np.mean(np.abs(y_test - y_pred))\n",
    "    print(f\"  Test MAE = {mae:.3f}\")\n",
    "\n",
    "for service in service_types:\n",
    "    # List of models\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest': RandomForestRegressor(),\n",
    "        'LightGBM': LGBMRegressor(verbosity=-1),\n",
    "        'XGBoost': XGBRegressor(verbosity=0)\n",
    "    }\n",
    "\n",
    "    eval = {model: {'mae': None, 'latency': None} for model in models.keys()}\n",
    "\n",
    "    # Filter the data for the current service type\n",
    "    service_data = Service_Type[Service_Type['Service Request Type'] == service].drop(columns=['Service Request Type'])\n",
    "    X = service_data.drop(columns=['Request Count'])\n",
    "    y = service_data['Request Count']\n",
    "\n",
    "    split_point = int(0.8 * len(X))\n",
    "    X_train = X.iloc[:split_point]\n",
    "    X_test = X.iloc[split_point:]\n",
    "    y_train = y.iloc[:split_point]\n",
    "    y_test = y.iloc[split_point:]\n",
    "\n",
    "    # Check if enough samples for 5-fold CV\n",
    "    if len(X_train) < 5:\n",
    "        print(f\"Skipping {service}: only {len(X_train)} samples.\")\n",
    "        continue\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        mean_absolute_errors, mean_absolute_percentage_errors, latencies = [], [], []\n",
    "\n",
    "        for idx_train, idx_val in cv_split.split(X_train, y_train):\n",
    "            # Split the data into training and validation sets\n",
    "            X_train_f = X_train.iloc[idx_train]\n",
    "            X_val = X_train.iloc[idx_val]\n",
    "            y_train_f = y_train.iloc[idx_train]\n",
    "            y_val = y_train.iloc[idx_val]\n",
    "\n",
    "            # Train the model\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train_f, y_train_f)\n",
    "\n",
    "            # Predict and evaluate\n",
    "            y_pred = model.predict(X_val)\n",
    "            end_time = time.time()\n",
    "\n",
    "            latency = end_time - start_time\n",
    "\n",
    "            # Store metrics for the model\n",
    "            mae = np.mean(np.abs(y_val - y_pred))\n",
    "            mape = np.mean(np.abs(100.0 * (y_val - y_pred) / y_val))\n",
    "            mean_absolute_errors.append(mae)\n",
    "            mean_absolute_percentage_errors.append(mape)\n",
    "            latencies.append(latency)\n",
    "\n",
    "        # Store averaged metrics for the model\n",
    "        eval[model_name]['mae'] = np.mean(mean_absolute_errors)\n",
    "        eval[model_name]['mape'] = np.mean(mean_absolute_percentage_errors)\n",
    "        eval[model_name]['latency'] = np.mean(latencies)\n",
    "\n",
    "    # Find the best model for the current service type\n",
    "    best_model = min(eval, key=lambda x: eval[x]['mape'])\n",
    "\n",
    "    # Update model_df cleanly\n",
    "    model_df.loc[model_df['Service Request Type'] == service, 'Model'] = best_model\n",
    "    model_df.loc[model_df['Service Request Type'] == service, 'Mean Absolute Error'] = eval[best_model]['mae']\n",
    "    model_df.loc[model_df['Service Request Type'] == service, 'Mean Absolute Percentage Error'] = eval[best_model]['mape']\n",
    "    model_df.loc[model_df['Service Request Type'] == service, 'Latency'] = eval[best_model]['latency']\n",
    "\n",
    "    for service_model in model_df['Service Request Type']:\n",
    "        print(f\"Service: {service_model}, Model: {model_df.loc[model_df['Service Request Type'] == service_model, 'Model'].values[0]}, \\\n",
    "              MAPE: {model_df.loc[model_df['Service Request Type'] == service_model, 'Mean Absolute Percentage Error'].values[0]:.2f}%, \\\n",
    "              Latency: {model_df.loc[model_df['Service Request Type'] == service_model, 'Latency'].values[0]:.2f} seconds\")\n",
    "\n",
    "    # Tune Hyperparameters\n",
    "    for service_model in model_df['Service Request Type']:\n",
    "\n",
    "        param_dist = {\n",
    "            'n_estimators': randint(100, 500),\n",
    "            'max_depth': [None] + list(range(10, 50, 10)),\n",
    "            'min_samples_split': randint(2, 10),\n",
    "            'min_samples_leaf': randint(1, 5),\n",
    "            'max_features': ['sqrt', 'log2'],\n",
    "            'bootstrap': [True, False]\n",
    "        }\n",
    "\n",
    "        rf = RandomizedSearchCV(\n",
    "            rf,\n",
    "            param_distributions=param_dist,\n",
    "            n_iter=20,\n",
    "            cv=5,\n",
    "            scoring='accuracy',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Recalibrate metrics using test set\n",
    "        rf.fit(X_train_lbl, y_train_lbl)\n",
    "\n",
    "        start_time = time.time()\n",
    "        rf_pred = rf.predict(X_test_lbl)\n",
    "        end_time = time.time()\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test_lbl, rf_pred).ravel()\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        latency = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3e410106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Define your base models + their param grids once, _outside_ the service‐loop\n",
    "base_models = {\n",
    "    'Linear Regression': (\n",
    "        LinearRegression(),\n",
    "        {\n",
    "            'fit_intercept': [True, False],\n",
    "            'normalize':     [True, False]\n",
    "        }\n",
    "    ),\n",
    "    'Random Forest': (\n",
    "        RandomForestRegressor(random_state=42),\n",
    "        {\n",
    "            'n_estimators':       randint(50, 300),\n",
    "            'max_depth':          randint(3, 20),\n",
    "            'min_samples_split':  randint(2, 10),\n",
    "            'min_samples_leaf':   randint(1, 10),\n",
    "            'max_features':       ['auto','sqrt','log2']\n",
    "        }\n",
    "    ),\n",
    "    'LightGBM': (\n",
    "        LGBMRegressor(verbosity=-1, random_state=42),\n",
    "        {\n",
    "            'n_estimators':       randint(50, 300),\n",
    "            'num_leaves':         randint(10, 200),\n",
    "            'learning_rate':      uniform(0.01, 0.3),\n",
    "            'min_child_samples':  randint(5, 50),\n",
    "            'subsample':          uniform(0.5, 0.5)\n",
    "        }\n",
    "    ),\n",
    "    'XGBoost': (\n",
    "        XGBRegressor(verbosity=0, random_state=42),\n",
    "        {\n",
    "            'n_estimators':       randint(50, 300),\n",
    "            'max_depth':          randint(3, 20),\n",
    "            'learning_rate':      uniform(0.01, 0.3),\n",
    "            'subsample':          uniform(0.5, 0.5),\n",
    "            'colsample_bytree':   uniform(0.5, 0.5)\n",
    "        }\n",
    "    ),\n",
    "}\n",
    "\n",
    "# 2) In your per‐service loop, replace the simple fit() with a RandomizedSearchCV fit:\n",
    "for service in service_types:\n",
    "    # pull out X_train_service, y_train_service, etc. as you already do…\n",
    "    # skip if <5 samples…\n",
    "\n",
    "    for model_name, (estimator, param_grid) in base_models.items():\n",
    "        # set up the RandomizedSearch over that one model\n",
    "        rs = RandomizedSearchCV(\n",
    "            estimator=estimator,\n",
    "            param_distributions=param_grid,\n",
    "            n_iter=20,\n",
    "            cv=5,\n",
    "            scoring='neg_mean_absolute_error',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # fit the search on your _filtered_ service‐type data\n",
    "        rs.fit(X_train_service, y_train_service)\n",
    "\n",
    "        # grab the best estimator & evaluate on your hold‐out fold(s)\n",
    "        best = rs.best_estimator_\n",
    "        y_pred = best.predict(X_test_service)   # or inside your CV if you want CV‐based MAPE\n",
    "        mae  = np.mean(np.abs(y_test_service - y_pred))\n",
    "        mape = np.mean(np.abs(100*(y_test_service - y_pred)/y_test_service))\n",
    "        lat  = rs.refit_time_  # or measure predict time yourself\n",
    "\n",
    "        # stash into model_df\n",
    "        model_df.loc[\n",
    "            (model_df['Service Request Type']==service) &\n",
    "            (model_df['Model']==model_name),\n",
    "            ['Mean Absolute Error','Mean Absolute Percentage Error','Latency']\n",
    "        ] = [mae, mape, lat]\n",
    "\n",
    "    print(f\"Finished tuning all models for {service}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f262db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = model_df.loc[model_df['Model'].notna(), :]\n",
    "model_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
